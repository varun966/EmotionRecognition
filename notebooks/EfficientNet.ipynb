{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e139819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.10.1\n",
      "CUDA Built:  True\n",
      "GPU:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(\"CUDA Built: \", tf.test.is_built_with_cuda())\n",
    "print(\"GPU: \", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2110884e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Growth Set\n"
     ]
    }
   ],
   "source": [
    "# Setting memory growth\n",
    "# By Default, Tensorflow may allocate all GPU memory at once, which can cause issue if \n",
    "# you're running multiple GPU applications\n",
    "# set memory growth tells Tensorflow to only allocate memory as needed, dynamically growing the memory footprint as needed\n",
    "# This helps avoid out-of-memory errors and allows multiple programs to share GPU efficiently/safely\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"Memory Growth Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b642e052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Activation, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as preprocess_mobile\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_efficient\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354c2b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as varun966\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as varun966\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"varun966/EmotionRecognition\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"varun966/EmotionRecognition\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository varun966/EmotionRecognition initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository varun966/EmotionRecognition initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/c2681ea7d2494a459bebc5b988ddf649', creation_time=1753187636321, experiment_id='1', last_update_time=1753187636321, lifecycle_stage='active', name='Efficient Net Experiment', tags={}>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/varun966/EmotionRecognition.mlflow')\n",
    "dagshub.init(repo_owner='varun966', repo_name='EmotionRecognition', mlflow=True)\n",
    "\n",
    "mlflow.set_experiment(\"Efficient Net Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75b03d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cea079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONST\n",
    "img_shape = (224,224,3)\n",
    "drop_layers = -5\n",
    "trainable_layers = -1\n",
    "Epochs = 30\n",
    "Verbose = 1\n",
    "batch_size = 8\n",
    "train_path = r'D:/AIML/fer2013/train'\n",
    "test_path = r'D:/AIML/fer2013/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd95ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before model training, clear Keras session to free old graphs and memory.\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09379c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fabec076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5741 images belonging to 7 classes.\n",
      "Epoch 1/30\n",
      "2871/2871 [==============================] - 412s 141ms/step - loss: 1.8932 - accuracy: 0.3405 - val_loss: 1.5195 - val_accuracy: 0.5029 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "2871/2871 [==============================] - 425s 148ms/step - loss: 1.5319 - accuracy: 0.4901 - val_loss: 1.3036 - val_accuracy: 0.5786 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "2871/2871 [==============================] - 413s 144ms/step - loss: 1.3756 - accuracy: 0.5448 - val_loss: 1.2395 - val_accuracy: 0.5943 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "2871/2871 [==============================] - 413s 144ms/step - loss: 1.2503 - accuracy: 0.5794 - val_loss: 1.1949 - val_accuracy: 0.6058 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "2871/2871 [==============================] - 414s 144ms/step - loss: 1.1569 - accuracy: 0.6048 - val_loss: 1.1758 - val_accuracy: 0.6156 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "2871/2871 [==============================] - 413s 144ms/step - loss: 1.0941 - accuracy: 0.6203 - val_loss: 1.1076 - val_accuracy: 0.6300 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "2871/2871 [==============================] - 412s 143ms/step - loss: 1.0206 - accuracy: 0.6347 - val_loss: 1.1406 - val_accuracy: 0.6187 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "2871/2871 [==============================] - 414s 144ms/step - loss: 0.9629 - accuracy: 0.6534 - val_loss: 1.0581 - val_accuracy: 0.6474 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "2871/2871 [==============================] - 414s 144ms/step - loss: 0.9176 - accuracy: 0.6661 - val_loss: 1.0285 - val_accuracy: 0.6502 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "2871/2871 [==============================] - 412s 143ms/step - loss: 0.8749 - accuracy: 0.6772 - val_loss: 1.0693 - val_accuracy: 0.6476 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "2871/2871 [==============================] - 434s 151ms/step - loss: 0.8453 - accuracy: 0.6889 - val_loss: 1.0393 - val_accuracy: 0.6569 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "2871/2871 [==============================] - 437s 152ms/step - loss: 0.7940 - accuracy: 0.7040 - val_loss: 1.0251 - val_accuracy: 0.6638 - lr: 1.0000e-04\n",
      "Epoch 13/30\n",
      "2871/2871 [==============================] - 446s 155ms/step - loss: 0.7757 - accuracy: 0.7109 - val_loss: 1.0592 - val_accuracy: 0.6654 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "2871/2871 [==============================] - 427s 149ms/step - loss: 0.7297 - accuracy: 0.7252 - val_loss: 1.0387 - val_accuracy: 0.6671 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "2871/2871 [==============================] - ETA: 0s - loss: 0.7103 - accuracy: 0.7337\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "2871/2871 [==============================] - 433s 151ms/step - loss: 0.7103 - accuracy: 0.7337 - val_loss: 1.0964 - val_accuracy: 0.6638 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "2871/2871 [==============================] - 414s 144ms/step - loss: 0.6264 - accuracy: 0.7621 - val_loss: 1.0791 - val_accuracy: 0.6751 - lr: 5.0000e-05\n",
      "Epoch 17/30\n",
      "2871/2871 [==============================] - 414s 144ms/step - loss: 0.5880 - accuracy: 0.7790 - val_loss: 1.0749 - val_accuracy: 0.6739 - lr: 5.0000e-05\n",
      "Epoch 18/30\n",
      "2871/2871 [==============================] - ETA: 0s - loss: 0.5641 - accuracy: 0.7854\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "2871/2871 [==============================] - 414s 144ms/step - loss: 0.5641 - accuracy: 0.7854 - val_loss: 1.1270 - val_accuracy: 0.6689 - lr: 5.0000e-05\n",
      "Epoch 19/30\n",
      "2871/2871 [==============================] - 415s 144ms/step - loss: 0.5162 - accuracy: 0.8087 - val_loss: 1.1332 - val_accuracy: 0.6729 - lr: 2.5000e-05\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Training failed: Unable to serialize [2.0896919 2.1128857 2.1081853] to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run gaudy-snake-756 at: https://dagshub.com/varun966/EmotionRecognition.mlflow/#/experiments/1/runs/692a1211e8db4c6a8f90279d5b6f6017\n",
      "🧪 View experiment at: https://dagshub.com/varun966/EmotionRecognition.mlflow/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------- Start MLflow Run --------------------\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "\n",
    "    # mlflow.log_param(\"Preprocessing\", [\n",
    "    #     \"Grayscale\",\n",
    "    #     \"Histogram Equalization\",\n",
    "    #     \"Resize((224,224), interpolation=cv.INTER_CUBIC) \",\n",
    "    #     #\"Blurring, (cv.GaussianBlur(resized_img, (3, 3), 0))\",\n",
    "    #     \"Blurring, (cv.createCLAHE(clipLimit=2.0, tileGridSize=(8,8)))\",\n",
    "    #     \"Shapening, (cv.addWeighted(blurred, 1.5, blurred, -0.5, 0))\"\n",
    "\n",
    "    # ])\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Creating the model\")\n",
    "\n",
    "        # Load EfficientNetB0 as base model\n",
    "        base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=img_shape)\n",
    "        base_model.trainable = True\n",
    "        mlflow.log_param(\"input_shape\", img_shape)\n",
    "        mlflow.log_param(\"pre_loaded_weights\", \"imagenet\")\n",
    "        mlflow.log_param(\"drop_layers\", drop_layers)\n",
    "\n",
    "        # Freeze all layers initially\n",
    "        # for layer in base_model.layers:\n",
    "        #     layer.trainable = True\n",
    "\n",
    "        # # Unfreeze last `trainable_layers` if specified\n",
    "        # if trainable_layers > 0:\n",
    "        #     for layer in base_model.layers[-trainable_layers:]:\n",
    "        #         layer.trainable = True\n",
    "        # elif trainable_layers == -1:\n",
    "        #     for layer in base_model.layers:\n",
    "        #         layer.trainable = True\n",
    "\n",
    "        mlflow.log_param(\"trainable_layers\", trainable_layers)\n",
    "\n",
    "        # Build full model with custom head\n",
    "        x = base_model.output\n",
    "        x = GlobalAveragePooling2D(name='global_avg_pool')(x)\n",
    "        x = Dropout(0.4, name='dropout_x')(x)\n",
    "        # x = Dense(256, activation='relu', kernel_regularizer=l2(0.001), name='dense_1')(x)\n",
    "        # x = Dropout(0.3, name='dropout_2')(x)\n",
    "        x = Dense(128, activation='relu', kernel_regularizer=l2(0.001), name='dense_2')(x)\n",
    "        x = Dropout(0.3, name='dropout_3')(x)\n",
    "        outputs = Dense(7, activation='softmax', name='output', dtype='float32')(x)\n",
    "\n",
    "        model = Model(inputs=base_model.input, outputs=outputs)\n",
    "\n",
    "        trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "        non_trainable_params = np.sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
    "        total_params = trainable_params + non_trainable_params\n",
    "\n",
    "        mlflow.log_param(\"trainable_params\", int(trainable_params))\n",
    "        mlflow.log_param(\"non_trainable_params\", int(non_trainable_params))\n",
    "        mlflow.log_param(\"total_params\", int(total_params))\n",
    "\n",
    "        mlflow.log_param(\"custom_layers\", [\n",
    "            \"GlobalAveragePooling2D\",\n",
    "            \"Dropout(0.4)\",\n",
    "            # \"Dense(256, relu, L2=0.001)\",\n",
    "            # \"Dropout(0.3)\",\n",
    "            \"Dense(128, relu, L2=0.001)\",\n",
    "            \"Dropout(0.3)\",\n",
    "            \"Dense(7, softmax)\"\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=Adam(learning_rate=1e-4),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        # -------------------- Data Augmentation --------------------\n",
    "        # augmentation_params = {\n",
    "        #     \"rotation_range\": 10,\n",
    "        #     \"zoom_range\": 0.1,\n",
    "        #     \"width_shift_range\": 0.1,\n",
    "        #     \"height_shift_range\": 0.1,\n",
    "        #     \"shear_range\": 0.1,\n",
    "        #     \"horizontal_flip\": True,\n",
    "        #     \"fill_mode\": 'nearest'\n",
    "        # }\n",
    "\n",
    "        # augmentation_params = {\n",
    "        #     \"rotation_range\": 10,\n",
    "        #     \"zoom_range\": [0.1, 1.2],\n",
    "        #     \"width_shift_range\": 0.1,\n",
    "        #     \"height_shift_range\": 0.1,\n",
    "        #     \"shear_range\": 0.1,\n",
    "        #     \"horizontal_flip\": True,\n",
    "        #     \"fill_mode\": 'nearest',\n",
    "        #     \"brightness_range\": [0.8, 1.2],\n",
    "        #     \"channel_shift_range\": 30.0\n",
    "        # }\n",
    "\n",
    "        augmentation_params = {\n",
    "        \"rotation_range\" :  15,\n",
    "        \"zoom_range\" : 0.15,\n",
    "        \"width_shift_range\": 0.1,\n",
    "        \"height_shift_range\": 0.1,\n",
    "        \"shear_range\" : 0.1,\n",
    "        \"horizontal_flip\" : True,\n",
    "        \"fill_mode\" : 'nearest',\n",
    "\n",
    "        }\n",
    "        mlflow.log_params(augmentation_params)\n",
    "\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_efficient,\n",
    "            validation_split=0.2,\n",
    "            **augmentation_params\n",
    "        )\n",
    "\n",
    "        val_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_efficient,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            directory=train_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training',\n",
    "            shuffle=True,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_generator = val_datagen.flow_from_directory(\n",
    "            directory=train_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation',\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(train_generator.classes),\n",
    "            y=train_generator.classes)\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        # -------------------- Callbacks --------------------\n",
    "        lr_schedule = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "        # -------------------- Training --------------------\n",
    "        history = model.fit(\n",
    "            x=train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=Epochs,\n",
    "            verbose=Verbose,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=[lr_schedule, early_stop]\n",
    "        )\n",
    "\n",
    "        end_time = time.time()\n",
    "        training_duration = end_time - start_time\n",
    "\n",
    "        # 📝 Log training time as metric in seconds or minutes\n",
    "        mlflow.log_metric(\"training_time_seconds\", training_duration)\n",
    "        mlflow.log_metric(\"training_time_minutes\", training_duration / 60)\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"train_accuracy\": history.history['accuracy'][-1],\n",
    "            \"val_accuracy\": history.history['val_accuracy'][-1],\n",
    "            \"train_loss\": history.history['loss'][-1],\n",
    "            \"val_loss\": history.history['val_loss'][-1]\n",
    "        })\n",
    "\n",
    "        # -------------------- Save Model Summary --------------------\n",
    "        with open(\"model_summary.txt\", \"w\") as f:\n",
    "            model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "        mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "        # -------------------- Testing --------------------\n",
    "        start_time_test = time.time()\n",
    "        test_batches = ImageDataGenerator(preprocessing_function=preprocess_efficient).flow_from_directory(\n",
    "            directory=test_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=10,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        num_test_records = test_batches.n\n",
    "\n",
    "        test_labels = test_batches.classes\n",
    "        predictions = model.predict(x=test_batches, verbose=0)\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "        end_time_test = time.time()\n",
    "\n",
    "        total_test_time = (end_time_test - start_time_test)\n",
    "        test_time_per_image = total_test_time / num_test_records\n",
    "        fps = num_test_records / total_test_time\n",
    "\n",
    "\n",
    "        test_accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "        test_f1_weighted = f1_score(test_labels, predicted_labels, average='weighted')\n",
    "        test_f1_macro = f1_score(test_labels, predicted_labels, average='macro')\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"test_accuracy\": test_accuracy,\n",
    "            \"test_f1_weighted\": test_f1_weighted,\n",
    "            \"test_f1_macro\": test_f1_macro,\n",
    "            \"total_test_duration\": total_test_time,\n",
    "            \"test_time_per_image\": test_time_per_image,\n",
    "            \"number_of_test_records\": num_test_records,\n",
    "            \"FPS\": fps\n",
    "\n",
    "        })\n",
    "\n",
    "        # -------------------- Classification Report --------------------\n",
    "        class_report = classification_report(test_labels, predicted_labels, output_dict=False)\n",
    "        with open(\"classification_report.txt\", \"w\") as f:\n",
    "            f.write(class_report)\n",
    "        mlflow.log_artifact(\"classification_report.txt\")\n",
    "\n",
    "        # -------------------- Confusion Matrix --------------------\n",
    "        cm = confusion_matrix(test_labels, predicted_labels)\n",
    "        np.savetxt(\"confusion_matrix.csv\", cm, delimiter=\",\", fmt=\"%d\")\n",
    "        mlflow.log_artifact(\"confusion_matrix.csv\")\n",
    "\n",
    "\n",
    "        # ----------------Model Logging\n",
    "        model.save('effnet_best_model.h5')\n",
    "        mlflow.log_artifact('effnet_best_model.h5')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    except Exception as e:\n",
    "        mlflow.log_param(\"error\", str(e))\n",
    "        logging.error(\"Training failed: %s\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a866e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
