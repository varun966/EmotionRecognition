{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5e8e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version:  2.10.1\n",
      "CUDA Built:  True\n",
      "GPU:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(\"CUDA Built: \", tf.test.is_built_with_cuda())\n",
    "print(\"GPU: \", tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6e39a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Growth Set\n"
     ]
    }
   ],
   "source": [
    "# Setting memory growth\n",
    "# By Default, Tensorflow may allocate all GPU memory at once, which can cause issue if \n",
    "# you're running multiple GPU applications\n",
    "# set memory growth tells Tensorflow to only allocate memory as needed, dynamically growing the memory footprint as needed\n",
    "# This helps avoid out-of-memory errors and allows multiple programs to share GPU efficiently/safely\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    print(\"Memory Growth Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14882053",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input as preprocess_mobile\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_efficient\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2 as cv\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b67779fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as varun966\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as varun966\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"varun966/EmotionRecognition\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"varun966/EmotionRecognition\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository varun966/EmotionRecognition initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository varun966/EmotionRecognition initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/5463f7ad9066475d87089177ad7424de', creation_time=1752684143899, experiment_id='0', last_update_time=1752684143899, lifecycle_stage='active', name='Mobile Net Experiment', tags={}>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/varun966/EmotionRecognition.mlflow')\n",
    "dagshub.init(repo_owner='varun966', repo_name='EmotionRecognition', mlflow=True)\n",
    "\n",
    "mlflow.set_experiment(\"Mobile Net Experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16f6d68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81e6ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONST\n",
    "img_shape = (128,128,3)\n",
    "drop_layers = -5\n",
    "trainable_layers = 50\n",
    "Epochs = 30\n",
    "Verbose = 1\n",
    "batch_size = 16\n",
    "train_path = r'D:/AIML/fer2013/train'\n",
    "test_path = r'D:/AIML/fer2013/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98cb9a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before model training, clear Keras session to free old graphs and memory.\n",
    "from tensorflow.keras import backend as K\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91546a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Training failed: When setting `include_top=True` and loading `imagenet` weights, `input_shape` should be (224, 224, 3).  Received: input_shape=(96, 96, 3)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bright-croc-158 at: https://dagshub.com/varun966/EmotionRecognition.mlflow/#/experiments/0/runs/78938aa9cb764e4e8d25bf1bf40f53fb\n",
      "üß™ View experiment at: https://dagshub.com/varun966/EmotionRecognition.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "def preprocess_mobile(x):\n",
    "    from keras.applications.mobilenet import preprocess_input\n",
    "    return preprocess_input(x)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Creating the model\")\n",
    "\n",
    "        # MobileNet Model\n",
    "        mobile = MobileNet(weights='imagenet', input_shape=img_shape)\n",
    "        mobile_model = Sequential()\n",
    "\n",
    "        mlflow.log_param(\"input_shape\", img_shape)\n",
    "        mlflow.log_param(\"pre_loaded_weights\", \"imagenet\")\n",
    "        mlflow.log_param(\"drop_layers\", drop_layers)\n",
    "\n",
    "        for layer in mobile.layers[:drop_layers]:\n",
    "            mobile_model.add(layer)\n",
    "\n",
    "        if trainable_layers == 0:\n",
    "            mobile_model.trainable = False\n",
    "        elif trainable_layers == 1:\n",
    "            mobile_model.trainable = True\n",
    "        elif trainable_layers < 0:\n",
    "            for layer in mobile_model.layers[:trainable_layers]:\n",
    "                layer.trainable = False\n",
    "            for layer in mobile_model.layers[trainable_layers:]:\n",
    "                layer.trainable = True\n",
    "\n",
    "        mlflow.log_param(\"trainable_layers\", trainable_layers)\n",
    "\n",
    "        trainable_params = np.sum([np.prod(v.get_shape()) for v in mobile_model.trainable_weights])\n",
    "        non_trainable_params = np.sum([np.prod(v.get_shape()) for v in mobile_model.non_trainable_weights])\n",
    "        total_params = trainable_params + non_trainable_params\n",
    "\n",
    "        mlflow.log_param(\"trainable_params\", int(trainable_params))\n",
    "        mlflow.log_param(\"non_trainable_params\", int(non_trainable_params))\n",
    "        mlflow.log_param(\"total_params\", int(total_params))\n",
    "\n",
    "        # Add custom layers\n",
    "        mobile_model.add(GlobalAveragePooling2D())\n",
    "        mobile_model.add(Dropout(0.5, name='dropout_x'))\n",
    "        mobile_model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001), name='dense_1'))\n",
    "        mobile_model.add(Dropout(0.3, name='dropout_2'))\n",
    "        mobile_model.add(Dense(7, activation='softmax', name='output', dtype='float32'))\n",
    "\n",
    "        mobile_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
    "\n",
    "        # Data generators\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_mobile,\n",
    "            rotation_range=10,\n",
    "            zoom_range=0.1,\n",
    "            width_shift_range=0.1,\n",
    "            height_shift_range=0.1,\n",
    "            shear_range=0.1,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest',\n",
    "            validation_split=0.2\n",
    "        )\n",
    "\n",
    "        val_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_mobile,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            directory=train_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training',\n",
    "            shuffle=True,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_generator = val_datagen.flow_from_directory(\n",
    "            directory=train_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation',\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(train_generator.classes),\n",
    "            y=train_generator.classes)\n",
    "\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        # Callbacks\n",
    "        lr_schedule = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "        # Train model\n",
    "        history = mobile_model.fit(\n",
    "            x=train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=Epochs,\n",
    "            verbose=Verbose,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=[lr_schedule, early_stop]\n",
    "        )\n",
    "\n",
    "        # Log training metrics\n",
    "        mlflow.log_metric(\"train_accuracy\", history.history['accuracy'][-1])\n",
    "        mlflow.log_metric(\"val_accuracy\", history.history['val_accuracy'][-1])\n",
    "        mlflow.log_metric(\"train_loss\", history.history['loss'][-1])\n",
    "        mlflow.log_metric(\"val_loss\", history.history['val_loss'][-1])\n",
    "\n",
    "        # Test metrics\n",
    "        test_batches = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_mobile).flow_from_directory(\n",
    "            directory=test_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=10,\n",
    "            shuffle=False,\n",
    "        )\n",
    "\n",
    "        test_labels = test_batches.classes\n",
    "\n",
    "        predictions = mobile_model.predict(x=test_batches, verbose=0)\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "        test_accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "        test_f1_weighted = f1_score(test_labels, predicted_labels, average='weighted')\n",
    "        test_f1_macro = f1_score(test_labels, predicted_labels, average='macro')\n",
    "\n",
    "        mlflow.log_metric(\"test_accuracy\", test_accuracy)\n",
    "        mlflow.log_metric(\"test_f1_weighted\", test_f1_weighted)\n",
    "        mlflow.log_metric(\"test_f1_macro\", test_f1_macro)\n",
    "\n",
    "    except Exception as e:\n",
    "        mlflow.log_param(\"error\", str(e))\n",
    "        logging.error(\"Training failed: %s\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95539be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5741 images belonging to 7 classes.\n",
      "Epoch 1/30\n",
      "  81/1436 [>.............................] - ETA: 2:02 - loss: 2.8849 - accuracy: 0.1759"
     ]
    }
   ],
   "source": [
    "\n",
    "# -------------------- Start MLflow Run --------------------\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        logging.info(\"Creating the model\")\n",
    "\n",
    "        # Load base model\n",
    "        base_model = MobileNet(weights='imagenet', input_shape=img_shape)\n",
    "        model = Sequential()\n",
    "\n",
    "        mlflow.log_param(\"input_shape\", img_shape)\n",
    "        mlflow.log_param(\"pre_loaded_weights\", \"imagenet\")\n",
    "        mlflow.log_param(\"drop_layers\", drop_layers)\n",
    "\n",
    "        for layer in base_model.layers[:drop_layers]:\n",
    "            model.add(layer)\n",
    "\n",
    "        if trainable_layers == 0:\n",
    "            model.trainable = False\n",
    "        elif trainable_layers == 1:\n",
    "            model.trainable = True\n",
    "        elif trainable_layers < 0:\n",
    "            for layer in model.layers[:trainable_layers]:\n",
    "                layer.trainable = False\n",
    "            for layer in model.layers[trainable_layers:]:\n",
    "                layer.trainable = True\n",
    "\n",
    "        mlflow.log_param(\"trainable_layers\", trainable_layers)\n",
    "\n",
    "        trainable_params = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
    "        non_trainable_params = np.sum([np.prod(v.get_shape()) for v in model.non_trainable_weights])\n",
    "        total_params = trainable_params + non_trainable_params\n",
    "\n",
    "        mlflow.log_param(\"trainable_params\", int(trainable_params))\n",
    "        mlflow.log_param(\"non_trainable_params\", int(non_trainable_params))\n",
    "        mlflow.log_param(\"total_params\", int(total_params))\n",
    "\n",
    "        # Custom Layers (logged individually)\n",
    "        model.add(GlobalAveragePooling2D(name='global_avg_pool'))\n",
    "        model.add(Dropout(0.5, name='dropout_x'))\n",
    "        model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001), name='dense_1'))\n",
    "        model.add(Dropout(0.3, name='dropout_2'))\n",
    "        model.add(Dense(7, activation='softmax', name='output', dtype='float32'))\n",
    "\n",
    "        mlflow.log_param(\"custom_layers\", [\n",
    "            \"GlobalAveragePooling2D\",\n",
    "            \"Dropout(0.5)\",\n",
    "            \"Dense(128, relu, L2=0.001)\",\n",
    "            \"Dropout(0.3)\",\n",
    "            \"Dense(7, softmax)\"\n",
    "        ])\n",
    "\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=Adam(learning_rate=1e-4),\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "        # -------------------- Data Augmentation --------------------\n",
    "        augmentation_params = {\n",
    "            \"rotation_range\": 10,\n",
    "            \"zoom_range\": 0.1,\n",
    "            \"width_shift_range\": 0.1,\n",
    "            \"height_shift_range\": 0.1,\n",
    "            \"shear_range\": 0.1,\n",
    "            \"horizontal_flip\": True,\n",
    "            \"fill_mode\": 'nearest'\n",
    "        }\n",
    "        mlflow.log_params(augmentation_params)\n",
    "\n",
    "        train_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_mobile,\n",
    "            validation_split=0.2,\n",
    "            **augmentation_params\n",
    "        )\n",
    "\n",
    "        val_datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_mobile,\n",
    "            validation_split=0.2\n",
    "        )\n",
    "\n",
    "        train_generator = train_datagen.flow_from_directory(\n",
    "            directory=train_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='training',\n",
    "            shuffle=True,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        val_generator = val_datagen.flow_from_directory(\n",
    "            directory=train_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            subset='validation',\n",
    "            shuffle=False,\n",
    "            seed=42\n",
    "        )\n",
    "\n",
    "        class_weights = class_weight.compute_class_weight(\n",
    "            class_weight='balanced',\n",
    "            classes=np.unique(train_generator.classes),\n",
    "            y=train_generator.classes)\n",
    "        class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "        # -------------------- Callbacks --------------------\n",
    "        lr_schedule = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "        early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "        # -------------------- Training --------------------\n",
    "        history = model.fit(\n",
    "            x=train_generator,\n",
    "            validation_data=val_generator,\n",
    "            epochs=Epochs,\n",
    "            verbose=Verbose,\n",
    "            class_weight=class_weights,\n",
    "            callbacks=[lr_schedule, early_stop]\n",
    "        )\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"train_accuracy\": history.history['accuracy'][-1],\n",
    "            \"val_accuracy\": history.history['val_accuracy'][-1],\n",
    "            \"train_loss\": history.history['loss'][-1],\n",
    "            \"val_loss\": history.history['val_loss'][-1]\n",
    "        })\n",
    "\n",
    "        # -------------------- Save Model Summary --------------------\n",
    "        with open(\"model_summary.txt\", \"w\") as f:\n",
    "            model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "        mlflow.log_artifact(\"model_summary.txt\")\n",
    "\n",
    "        # -------------------- Testing --------------------\n",
    "        test_batches = ImageDataGenerator(preprocessing_function=preprocess_mobile).flow_from_directory(\n",
    "            directory=test_path,\n",
    "            target_size=(224, 224),\n",
    "            batch_size=10,\n",
    "            shuffle=False\n",
    "        )\n",
    "\n",
    "        test_labels = test_batches.classes\n",
    "        predictions = model.predict(x=test_batches, verbose=0)\n",
    "        predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "        test_accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "        test_f1_weighted = f1_score(test_labels, predicted_labels, average='weighted')\n",
    "        test_f1_macro = f1_score(test_labels, predicted_labels, average='macro')\n",
    "\n",
    "        mlflow.log_metrics({\n",
    "            \"test_accuracy\": test_accuracy,\n",
    "            \"test_f1_weighted\": test_f1_weighted,\n",
    "            \"test_f1_macro\": test_f1_macro\n",
    "        })\n",
    "\n",
    "        # -------------------- Classification Report --------------------\n",
    "        class_report = classification_report(test_labels, predicted_labels, output_dict=False)\n",
    "        with open(\"classification_report.txt\", \"w\") as f:\n",
    "            f.write(class_report)\n",
    "        mlflow.log_artifact(\"classification_report.txt\")\n",
    "\n",
    "        # -------------------- Confusion Matrix --------------------\n",
    "        cm = confusion_matrix(test_labels, predicted_labels)\n",
    "        np.savetxt(\"confusion_matrix.csv\", cm, delimiter=\",\", fmt=\"%d\")\n",
    "        mlflow.log_artifact(\"confusion_matrix.csv\")\n",
    "\n",
    "    except Exception as e:\n",
    "        mlflow.log_param(\"error\", str(e))\n",
    "        logging.error(\"Training failed: %s\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945359b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atlas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
